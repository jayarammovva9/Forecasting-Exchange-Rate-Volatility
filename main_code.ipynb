{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzopO7brLLxl"
      },
      "outputs": [],
      "source": [
        "# ===================================================================\n",
        "# PART 0: INSTALL NECESSARY LIBRARIES\n",
        "# ===================================================================\n",
        "# This will correctly install the libraries for GARCH models and the DM test\n",
        "!pip install arch dieboldmariano --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import io\n",
        "import random\n",
        "\n",
        "# <<< FIX: Correctly import the DM test from the library we just installed >>>\n",
        "from dieboldmariano import dm_test\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
        "\n",
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Layer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Arch imports\n",
        "from arch import arch_model\n",
        "\n",
        "# ===================================================================\n",
        "# PART 1: SETUP AND DATA LOADING\n",
        "# ===================================================================\n",
        "# --- 1.1 Set Random Seed for Reproducibility ---\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "print(\"Global random seeds set.\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"IMPORTANT: FOR FASTER TRAINING, GO TO 'RUNTIME' > 'CHANGE RUNTIME TYPE'\")\n",
        "print(\"AND SELECT 'T4 GPU' AS THE HARDWARE ACCELERATOR.\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- 1.2 Load Data ---\n",
        "print(\"Please upload your 'final_predictors_2003_onwards.csv' file.\")\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]), index_col='Date', parse_dates=True)\n",
        "print(\"\\n--- Data Loaded Successfully ---\")\n",
        "\n",
        "# ===================================================================\n",
        "# PART 2: FEATURE ENGINEERING & TARGET VARIABLE\n",
        "# ===================================================================\n",
        "df['USDINR_log_return'] = np.log(df['USDINR'] / df['USDINR'].shift(1))\n",
        "df['SP500_log_return'] = np.log(df['SP500'] / df['SP500'].shift(1))\n",
        "df['OIL_WTI_log_return'] = np.log(df['OIL_WTI'] / df['OIL_WTI'].shift(1))\n",
        "df['GOLD_log_return'] = np.log(df['GOLD'] / df['GOLD'].shift(1))\n",
        "df['REALIZED_VOLATILITY'] = df['USDINR_log_return'].rolling(window=21).std() * np.sqrt(252)\n",
        "df['RV_d'] = df['REALIZED_VOLATILITY'].shift(1)\n",
        "df['RV_w'] = df['REALIZED_VOLATILITY'].shift(1).rolling(window=5).mean()\n",
        "df['RV_m'] = df['REALIZED_VOLATILITY'].shift(1).rolling(window=22).mean()\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# --- Define Feature Sets ---\n",
        "y = df['REALIZED_VOLATILITY']\n",
        "X_full = df.drop(columns=['REALIZED_VOLATILITY', 'USDINR', 'SP500', 'OIL_WTI', 'GOLD', 'USDINR_log_return'])\n",
        "X_simple = df[['RV_d', 'RV_w', 'RV_m']]\n",
        "\n",
        "# ===================================================================\n",
        "# PART 3: MODEL DEFINITIONS\n",
        "# ===================================================================\n",
        "# --- 3.1 LSTM Sequence Creation ---\n",
        "def create_sequences(X_data, y_data, window_size):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X_data) - window_size):\n",
        "        X_seq.append(X_data[i:(i + window_size)])\n",
        "        y_seq.append(y_data[i + window_size])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# --- 3.2 LSTM Model Builder ---\n",
        "class Attention(Layer):\n",
        "    def __init__(self, **kwargs): super(Attention, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1], 1), initializer='random_normal', trainable=True)\n",
        "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1], 1), initializer='zeros', trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x, self.W) + self.b); e = K.squeeze(e, axis=-1)\n",
        "        alpha = K.softmax(e); alpha = K.expand_dims(alpha, axis=-1)\n",
        "        context = x * alpha\n",
        "        return K.sum(context, axis=1)\n",
        "\n",
        "def build_lstm_model(window_size, n_features):\n",
        "    tf.random.set_seed(seed_value)\n",
        "    input_layer = Input(shape=(window_size, n_features))\n",
        "    lstm1 = LSTM(64, return_sequences=True)(input_layer)\n",
        "    dropout1 = Dropout(0.2)(lstm1)\n",
        "    lstm2 = LSTM(32, return_sequences=True)(dropout1)\n",
        "    attention = Attention()(lstm2)\n",
        "    dense1 = Dense(20, activation='relu')(attention)\n",
        "    output_layer = Dense(1)(dense1)\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# ===================================================================\n",
        "# PART 4: WALK-FORWARD VALIDATION (MODIFIED FOR SPEED)\n",
        "# ===================================================================\n",
        "print(\"\\n--- Starting Walk-Forward Validation (PROTOTYPING MODE) ---\")\n",
        "\n",
        "# --- 4.1 Define Split Parameters ---\n",
        "split_index = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:split_index]\n",
        "test_df = df.iloc[split_index:]\n",
        "\n",
        "n_folds = 14\n",
        "WINDOW_SIZE = 60\n",
        "EPOCHS_PROTOTYPE = 50\n",
        "\n",
        "n_test = len(test_df)\n",
        "FORECAST_CHUNK_SIZE = int(np.ceil(n_test / n_folds))\n",
        "print(f\"Test set size: {n_test} days. Forecasting in {n_folds} folds of ~{FORECAST_CHUNK_SIZE} days each.\")\n",
        "\n",
        "# --- 4.2 Create Lists to Store Results ---\n",
        "all_har_preds, all_garch_preds, all_gjr_preds, all_lstm_full_preds, all_lstm_simple_preds = [], [], [], [], []\n",
        "all_actuals = []\n",
        "\n",
        "# --- 4.3 Start the Walk-Forward Loop ---\n",
        "for i in range(n_folds):\n",
        "    print(f\"\\n--- Fold {i+1}/{n_folds} ---\")\n",
        "    start_idx = i * FORECAST_CHUNK_SIZE\n",
        "    end_idx = min((i + 1) * FORECAST_CHUNK_SIZE, n_test)\n",
        "\n",
        "    current_test_chunk = test_df.iloc[start_idx:end_idx]\n",
        "    if current_test_chunk.empty: continue\n",
        "    current_train_df = df.iloc[:split_index + start_idx]\n",
        "\n",
        "    y_test_fold = y.loc[current_test_chunk.index]\n",
        "    all_actuals.append(y_test_fold)\n",
        "\n",
        "    # --- 4.3.1 HAR-RV Model ---\n",
        "    X_har_train = X_simple.loc[current_train_df.index.intersection(X_simple.index)]\n",
        "    y_har_train = y.loc[X_har_train.index]\n",
        "    X_har_test = X_simple.loc[current_test_chunk.index.intersection(X_simple.index)]\n",
        "\n",
        "    if not X_har_test.empty:\n",
        "        har_model = LinearRegression()\n",
        "        har_model.fit(X_har_train, y_har_train)\n",
        "        har_preds = har_model.predict(X_har_test)\n",
        "        all_har_preds.append(pd.Series(har_preds, index=X_har_test.index, name=\"HAR_Forecast\"))\n",
        "\n",
        "    # --- 4.3.2 GARCH Models ---\n",
        "    returns_loop = current_train_df['USDINR_log_return'].dropna() * 100\n",
        "    horizon = len(current_test_chunk)\n",
        "    garch_model = arch_model(returns_loop, vol='Garch', p=1, q=1); garch_res = garch_model.fit(disp='off')\n",
        "    garch_preds = np.sqrt(garch_res.forecast(horizon=horizon, reindex=False).variance.values.flatten()) / 100 * np.sqrt(252)\n",
        "    all_garch_preds.append(pd.Series(garch_preds, index=y_test_fold.index, name=\"GARCH_Forecast\"))\n",
        "\n",
        "    gjr_model = arch_model(returns_loop, vol='Garch', p=1, o=1, q=1); gjr_res = gjr_model.fit(disp='off')\n",
        "    gjr_preds = np.sqrt(gjr_res.forecast(horizon=horizon, reindex=False).variance.values.flatten()) / 100 * np.sqrt(252)\n",
        "    all_gjr_preds.append(pd.Series(gjr_preds, index=y_test_fold.index, name=\"GJR_GARCH_Forecast\"))\n",
        "\n",
        "    # --- 4.3.3 **LSTM Models (Full and Simple)** ---\n",
        "    print(f\"Training LSTM models for Fold {i+1} (this may take a few minutes)...\")\n",
        "\n",
        "    # --- Full LSTM (with all features) ---\n",
        "    X_train_loop_full = X_full.loc[current_train_df.index]\n",
        "    y_train_loop = y.loc[current_train_df.index]\n",
        "    X_test_loop_full = X_full.loc[current_test_chunk.index]\n",
        "\n",
        "    fs_full = MinMaxScaler(); ts_full = MinMaxScaler()\n",
        "    X_train_scaled_full = fs_full.fit_transform(X_train_loop_full)\n",
        "    X_test_scaled_full = fs_full.transform(X_test_loop_full)\n",
        "    y_train_scaled = ts_full.fit_transform(y_train_loop.values.reshape(-1, 1))\n",
        "\n",
        "    X_train_seq, y_train_seq = create_sequences(X_train_scaled_full, y_train_scaled, WINDOW_SIZE)\n",
        "    combined_X_for_seq = np.concatenate((X_train_scaled_full[-WINDOW_SIZE:], X_test_scaled_full))\n",
        "    X_test_seq, _ = create_sequences(combined_X_for_seq, np.zeros(len(combined_X_for_seq)), WINDOW_SIZE)\n",
        "    X_test_seq_full = X_test_seq[:len(X_test_loop_full)]\n",
        "\n",
        "    model_full = build_lstm_model(WINDOW_SIZE, X_train_seq.shape[2])\n",
        "    model_full.fit(X_train_seq, y_train_seq, epochs=EPOCHS_PROTOTYPE, batch_size=32, validation_split=0.15, callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)], verbose=0)\n",
        "    lstm_preds_scaled = model_full.predict(X_test_seq_full)\n",
        "    lstm_preds_full = ts_full.inverse_transform(lstm_preds_scaled)\n",
        "    all_lstm_full_preds.append(pd.Series(lstm_preds_full.flatten(), index=y_test_fold.index, name=\"LSTM_Full_Forecast\"))\n",
        "\n",
        "    # --- Simple LSTM (with HAR features only) ---\n",
        "    X_train_loop_simple = X_simple.loc[current_train_df.index]\n",
        "    X_test_loop_simple = X_simple.loc[current_test_chunk.index]\n",
        "\n",
        "    fs_simple = MinMaxScaler(); ts_simple = MinMaxScaler()\n",
        "    X_train_scaled_simple = fs_simple.fit_transform(X_train_loop_simple)\n",
        "    X_test_scaled_simple = fs_simple.transform(X_test_loop_simple)\n",
        "    y_train_scaled_simple = ts_simple.fit_transform(y_train_loop.values.reshape(-1, 1))\n",
        "\n",
        "    X_train_seq_s, y_train_seq_s = create_sequences(X_train_scaled_simple, y_train_scaled_simple, WINDOW_SIZE)\n",
        "    combined_X_for_seq_s = np.concatenate((X_train_scaled_simple[-WINDOW_SIZE:], X_test_scaled_simple))\n",
        "    X_test_seq_s, _ = create_sequences(combined_X_for_seq_s, np.zeros(len(combined_X_for_seq_s)), WINDOW_SIZE)\n",
        "    X_test_seq_simple = X_test_seq_s[:len(X_test_loop_simple)]\n",
        "\n",
        "    model_simple = build_lstm_model(WINDOW_SIZE, X_train_seq_s.shape[2])\n",
        "    model_simple.fit(X_train_seq_s, y_train_seq_s, epochs=EPOCHS_PROTOTYPE, batch_size=32, validation_split=0.15, callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)], verbose=0)\n",
        "    lstm_preds_scaled_s = model_simple.predict(X_test_seq_simple)\n",
        "    lstm_preds_simple = ts_simple.inverse_transform(lstm_preds_scaled_s)\n",
        "    all_lstm_simple_preds.append(pd.Series(lstm_preds_simple.flatten(), index=y_test_fold.index, name=\"LSTM_Simple_Forecast\"))\n",
        "\n",
        "print(\"\\n--- Walk-Forward Validation Complete ---\")\n",
        "\n",
        "# ===================================================================\n",
        "# PART 5: RESULTS AND EVALUATION\n",
        "# ===================================================================\n",
        "print(\"\\n--- Comparing Model Performance ---\")\n",
        "\n",
        "# --- 5.1 Combine all results ---\n",
        "har_results = pd.concat(all_har_preds); garch_results = pd.concat(all_garch_preds); gjr_results = pd.concat(all_gjr_preds)\n",
        "lstm_full_results = pd.concat(all_lstm_full_preds); lstm_simple_results = pd.concat(all_lstm_simple_preds)\n",
        "actuals_results = pd.concat(all_actuals); actuals_results.name = 'REALIZED_VOLATILITY'\n",
        "\n",
        "results_df = pd.DataFrame(actuals_results)\n",
        "results_df = results_df.join(har_results, how='left').join(garch_results, how='left').join(gjr_results, how='left')\n",
        "results_df = results_df.join(lstm_full_results, how='left').join(lstm_simple_results, how='left')\n",
        "results_df.dropna(inplace=True)\n",
        "\n",
        "# --- 5.2 Calculate and Print Metrics ---\n",
        "models_to_evaluate = [\"HAR_Forecast\", \"GARCH_Forecast\", \"GJR_GARCH_Forecast\", \"LSTM_Full_Forecast\", \"LSTM_Simple_Forecast\"]\n",
        "metrics = {'Model': [], 'RMSE': [], 'MAE': []}\n",
        "for model_name in models_to_evaluate:\n",
        "    rmse = np.sqrt(mean_squared_error(results_df['REALIZED_VOLATILITY'], results_df[model_name]))\n",
        "    mae = mean_absolute_error(results_df['REALIZED_VOLATILITY'], results_df[model_name])\n",
        "    metrics['Model'].append(model_name)\n",
        "    metrics['RMSE'].append(rmse)\n",
        "    metrics['MAE'].append(mae)\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "print(\"\\n--- Final Model Metrics (Walk-Forward) ---\")\n",
        "print(metrics_df.round(6))\n",
        "\n",
        "\n",
        "# ===================================================================\n",
        "# PART 6: ECONOMIC SIGNIFICANCE (HEDGING SIMULATION)\n",
        "# ===================================================================\n",
        "print(\"\\n--- Part 6: Economic Significance (Hedging Simulation) ---\")\n",
        "\n",
        "volatility_threshold = y.loc[train_df.index].quantile(0.75)\n",
        "print(f\"Hedging Threshold (75th percentile of train vol): {volatility_threshold:.6f}\")\n",
        "\n",
        "results_df['Actual_Hedge'] = results_df['REALIZED_VOLATILITY'] > volatility_threshold\n",
        "for model_name in models_to_evaluate:\n",
        "    results_df[f'{model_name}_Hedge'] = results_df[model_name] > volatility_threshold\n",
        "\n",
        "decision_metrics = {'Model': [], 'Hedge_Accuracy': []}\n",
        "for model_name in models_to_evaluate:\n",
        "    accuracy = accuracy_score(results_df['Actual_Hedge'], results_df[f'{model_name}_Hedge'])\n",
        "    decision_metrics['Model'].append(model_name)\n",
        "    decision_metrics['Hedge_Accuracy'].append(accuracy)\n",
        "\n",
        "decision_metrics_df = pd.DataFrame(decision_metrics)\n",
        "print(\"\\n--- Hedging Decision Accuracy ---\")\n",
        "print(decision_metrics_df.round(4))\n",
        "\n",
        "# ===================================================================\n",
        "# PART 7: VISUALIZATION\n",
        "# ===================================================================\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(results_df['REALIZED_VOLATILITY'], label='Actual Volatility', color='black', linewidth=2)\n",
        "plt.plot(results_df['HAR_Forecast'], label='HAR-RV (Linear)', color='green', alpha=0.7, linestyle=':')\n",
        "plt.plot(results_df['LSTM_Simple_Forecast'], label='LSTM (Simple, HAR Features)', color='purple', alpha=0.8)\n",
        "plt.plot(results_df['LSTM_Full_Forecast'], label='LSTM (Full, All Features)', color='red', alpha=0.8, linestyle='--')\n",
        "plt.title('Walk-Forward Volatility Forecast Comparison')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Annualized Volatility')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    }
  ]
}